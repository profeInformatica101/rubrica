<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Herramientas Python en Ciberseguridad</title>
    <!-- Importar Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <style>
        code{
            color:darkred;
        }
    </style>
    <div class="container mt-5">
        <h1 class="mb-4">Herramientas Python en Ciberseguridad</h1>
        <p class="text-muted">Advertencia: Las herramientas y scripts presentados aquí deben usarse exclusivamente con fines educativos y en entornos controlados, con el permiso adecuado.</p>
        <table class="table table-bordered">
            <thead class="table-dark">
                <tr>
                    <th>Característica</th>
                    <th>Scrapy</th>
                    <th>Scapy</th>
                    <th>PyCrypto</th>
                    <th>Requests</th>
                    <th>Beautiful Soup</th>
                    <th>Nmap</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Enfoque</td>
                    <td>Web scraping y recolección de datos</td>
                    <td>Redes, ciberseguridad, análisis de tráfico</td>
                    <td>Cifrado y descifrado de datos</td>
                    <td>Interacción con servicios web</td>
                    <td>Manipulación y análisis de HTML/XML</td>
                    <td>Escaneo de redes y dispositivos</td>
                </tr>
                <tr>
                    <td>Nivel</td>
                    <td>Alto nivel: estructuración de datos web</td>
                    <td>Bajo nivel: manipulación directa de paquetes</td>
                    <td>Intermedio: seguridad en datos</td>
                    <td>Intermedio: peticiones HTTP</td>
                    <td>Intermedio: análisis de páginas web</td>
                    <td>Intermedio-avanzado: escaneo y auditoría</td>
                </tr>
                <tr>
                    <td>Ámbito</td>
                    <td>Scraping web</td>
                    <td>Redes y ciberseguridad</td>
                    <td>Seguridad de la información</td>
                    <td>Automatización de tareas web</td>
                    <td>Auditorías web</td>
                    <td>Análisis y descubrimiento de redes</td>
                </tr>
                <tr>
                    <td>Aplicaciones</td>
                    <td>
                        <ul>
                            <li>Auditoría de sitios web</li>
                            <li>Extracción de datos</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Simulación de ataques</li>
                            <li>Análisis de tráfico</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Cifrar archivos</li>
                            <li>Verificar integridad</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Pruebas de formularios</li>
                            <li>Scraping básico</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Scraping de enlaces</li>
                            <li>Validar HTML</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Identificación de puertos</li>
                            <li>Auditorías de vulnerabilidades</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Documentación oficial</td>
                    <td><a href="https://docs.scrapy.org/en/latest/" target="_blank">Scrapy Docs</a></td>
                    <td><a href="https://scapy.readthedocs.io/en/latest/" target="_blank">Scapy Docs</a></td>
                    <td><a href="https://pycryptodome.readthedocs.io/" target="_blank">PyCrypto Docs</a></td>
                    <td><a href="https://docs.python-requests.org/en/latest/" target="_blank">Requests Docs</a></td>
                    <td><a href="https://beautiful-soup-4.readthedocs.io/en/latest/" target="_blank">Beautiful Soup Docs</a></td>
                    <td><a href="https://nmap.org/docs.html" target="_blank">Nmap Docs</a></td>
                </tr>
            </tbody>
        </table>
        <div class="accordion" id="pythonToolsAccordion">
            <!-- Scrapy -->
<div class="accordion-item">
    <h2 class="accordion-header" id="headingScrapy">
        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseScrapy" aria-expanded="false" aria-controls="collapseScrapy">
            <i class="fas fa-robot me-2"></i> Scrapy
        </button>
    </h2>
    <div id="collapseScrapy" class="accordion-collapse collapse" aria-labelledby="headingScrapy" data-bs-parent="#pythonToolsAccordion">
        <div class="accordion-body">
            <p><strong>Scrapy</strong> es un framework de scraping de datos web que permite recolectar y estructurar información de manera eficiente.</p>
            <h5>Ejemplos prácticos:</h5>
            <ul>
                <li>Extraer títulos de artículos en una página web:
                    <pre>
                        <code>
import scrapy

class ArticleSpider(scrapy.Spider):
    name = 'articles'
    start_urls = ['https://example.com/blog']

    def parse(self, response):
        titles = response.css('h2.title::text').getall()
        for title in titles:
            yield {'title': title}
                        </code>
                    </pre>
                </li>
                <li>Crear un bot para recolectar precios de productos:
                    <pre>
                        <code>
import scrapy

class ProductSpider(scrapy.Spider):
    name = 'products'
    start_urls = ['https://example.com/store']

    def parse(self, response):
        for product in response.css('div.product'):
            yield {
                'name': product.css('h2::text').get(),
                'price': product.css('span.price::text').get(),
            }
                        </code>
                    </pre>
                </li>
            </ul>
            <a href="https://docs.scrapy.org/en/latest/" target="_blank">Documentación oficial de Scrapy</a>
        </div>
    </div>
</div>

            <!-- Scapy -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="headingScapy">
                    <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseScapy" aria-expanded="true" aria-controls="collapseScapy">
                        <i class="fas fa-network-wired me-2"></i> Scapy
                    </button>
                </h2>
                <div id="collapseScapy" class="accordion-collapse collapse show" aria-labelledby="headingScapy" data-bs-parent="#pythonToolsAccordion">
                    <div class="accordion-body">
                        <p><strong>Scapy</strong> es una herramienta poderosa para manipular paquetes de red. Es ideal para pruebas de penetración y análisis de redes.</p>
                        <h5>Ejemplos prácticos:</h5>
                        <ul>
                            <li>Simular un ataque de denegación de servicio (DoS): <code>send(IP(dst="192.168.1.1")/ICMP()*1000)</code></li>
                            <li>Analizar tráfico de red: <code>sniff(iface="eth0", count=10, prn=lambda x: x.summary())</code></li>
                            <li>Spoofing de IP: <code>send(IP(src="192.168.1.2", dst="192.168.1.3")/TCP(dport=80))</code></li>
                        </ul>
                        <a href="https://scapy.readthedocs.io/en/latest/" target="_blank">Documentación oficial de Scapy</a>
                    </div>
                    <pre>
                        <code>
                            from scapy.all import IP, ICMP, sr1
                            
                            packet = IP(dst="192.168.1.1")/ICMP()
                            response = sr1(packet)
                            print(response.summary())

                        </code>
                    </pre>
                </div>
            </div>
            <!-- PyCrypto -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="headingPyCrypto">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapsePyCrypto" aria-expanded="false" aria-controls="collapsePyCrypto">
                        <i class="fas fa-lock me-2"></i> PyCrypto
                    </button>
                </h2>
                <div id="collapsePyCrypto" class="accordion-collapse collapse" aria-labelledby="headingPyCrypto" data-bs-parent="#pythonToolsAccordion">
                    <div class="accordion-body">
                        <p><strong>PyCrypto</strong> proporciona herramientas para cifrar y descifrar datos, esenciales en la protección de información.</p>
                        <h5>Ejemplos prácticos:</h5>
                        <ul>
                            <li>Cifrar y descifrar archivos: <code>cipher = AES.new(key, AES.MODE_EAX); ciphertext = cipher.encrypt(data)</code></li>
                            <li>Verificar la integridad de los datos: <code>hash = SHA256.new(data).hexdigest()</code></li>
                        </ul>
                        <a href="https://pycryptodome.readthedocs.io/" target="_blank">Documentación oficial de PyCrypto</a>
                    </div>
                    <pre>
                        <code>
                            from Crypto.Cipher import AES
                            from Crypto.Random import get_random_bytes
    
                            # Clave y datos
                            key = get_random_bytes(16)  # AES requiere una clave de 16 bytes
                            data = b"Datos confidenciales"
    
                            # Cifrado
                            cipher = AES.new(key, AES.MODE_EAX)
                            ciphertext, tag = cipher.encrypt_and_digest(data)
    
                            # Descifrado
                            decipher = AES.new(key, AES.MODE_EAX, nonce=cipher.nonce)
                            plaintext = decipher.decrypt(ciphertext)
    
                            print("Texto descifrado:", plaintext.decode())
    
                        </code>
                    </pre>
                </div>

            </div>
            <!-- Requests -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="headingRequests">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseRequests" aria-expanded="false" aria-controls="collapseRequests">
                        <i class="fas fa-globe me-2"></i> Requests
                    </button>
                </h2>
                <div id="collapseRequests" class="accordion-collapse collapse" aria-labelledby="headingRequests" data-bs-parent="#pythonToolsAccordion">
                    <div class="accordion-body">
                        <p><strong>Requests</strong> simplifica las peticiones HTTP, facilitando la interacción con servicios web.</p>
                        <h5>Ejemplos prácticos:</h5>
                        <ul>
                            <li>Automatizar tareas web: <code>response = requests.get('https://example.com')</code></li>
                            <li>Realizar pruebas de seguridad: <code>requests.post('https://example.com/login', data={'user':'admin', 'pass':'123'})</code></li>
                        </ul>
                        <a href="https://docs.python-requests.org/en/latest/" target="_blank">Documentación oficial de Requests</a>
                        <pre>
                            <code>
                                import requests
                                response = requests.get('https://profeinformatica101.github.io/2bach/')
                                # Check for successful response (optional)
                                if response.status_code == 200:
                                    print("Successfully retrieved the webpage!")
                                else:
                                    print(f"Error: {response.status_code}")
                            </code>
                        </pre>
                    </div>
                </div>
            </div>
            <!-- Beautiful Soup -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="headingBeautifulSoup">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseBeautifulSoup" aria-expanded="false" aria-controls="collapseBeautifulSoup">
                        <i class="fas fa-code me-2"></i> Beautiful Soup
                    </button>
                </h2>
                <div id="collapseBeautifulSoup" class="accordion-collapse collapse" aria-labelledby="headingBeautifulSoup" data-bs-parent="#pythonToolsAccordion">
                    <div class="accordion-body">
                        <p><strong>Beautiful Soup</strong> permite analizar y manipular código HTML y XML para auditorías web.</p>
                        <h5>Ejemplos prácticos:</h5>
                        <ul>
                            <li>Extraer todos los enlaces de una página web: <code>links = soup.find_all('a')</code></li>
                            <li>Analizar el código HTML: <code>soup = BeautifulSoup(html_doc, 'html.parser')</code></li>
                        </ul>
                        <a href="https://beautiful-soup-4.readthedocs.io/en/latest/" target="_blank">Documentación oficial de Beautiful Soup</a>
                    </div>
                    <pre>
                        <code>
                            from bs4 import BeautifulSoup
                            import requests
    
                            # Obtener contenido HTML
                            url = "https://example.com"
                            response = requests.get(url)
                            html_content = response.text
    
                            # Analizar HTML
                            soup = BeautifulSoup(html_content, 'html.parser')
    
                            # Extraer todos los enlaces
                            for link in soup.find_all('a'):
                                print("Enlace encontrado:", link.get('href')
                        </code>
                    </pre>
                </div>
            
            </div>
            <!-- Nmap -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="headingNmap">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseNmap" aria-expanded="false" aria-controls="collapseNmap">
                        <i class="fas fa-server me-2"></i> Nmap
                    </button>
                </h2>
                <div id="collapseNmap" class="accordion-collapse collapse" aria-labelledby="headingNmap" data-bs-parent="#pythonToolsAccordion">
                    <div class="accordion-body">
                        <p><strong>Nmap</strong> es un escáner de red utilizado para identificar dispositivos y servicios en una red.</p>
                        <h5>Ejemplos prácticos:</h5>
                        <ul>
                            <li>Escaneo de puertos: <code>nm.scan('192.168.1.1', '22-80')</code></li>
                            <li>Encontrar vulnerabilidades: <code>nm.scan(hosts='192.168.1.0/24', arguments='-sV')</code></li>
                        </ul>
                        <a href="https://nmap.org/docs.html" target="_blank">Documentación oficial de Nmap</a>
                    </div>
                    <pre>
                        <code>
                    import nmap
                    
                    scanner = nmap.PortScanner()
                    scanner.scan('192.168.1.1', '1-1024', arguments='-sV')
                    
                    for host in scanner.all_hosts():
                        print(f"Host: {host} ({scanner[host].hostname()})")
                        print(f"Estado: {scanner[host].state()}")
                        for protocol in scanner[host].all_protocols():
                            print(f"Protocolo: {protocol}")
                            ports = scanner[host][protocol].keys()
                            for port in ports:
                                print(f"Puerto: {port}, Estado: {scanner[host][protocol][port]['state']}")
                        </code>
                    </pre>
                </div>
            </div>
        </div>
    </div>
    <!-- Importar Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
